{"cells":[{"cell_type":"markdown","metadata":{"id":"Iwarzy6Ugiy2"},"source":["# Importing data and libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7IMmwcFf2Kl"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import re\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0uLz_MSgq5E"},"outputs":[],"source":["df_auto = pd.read_excel('Pre Processing/automobile.xlsx', index_col=0)\n","df_fashion = pd.read_excel('Pre Processing/fashion.xlsx', index_col=0)\n","df_finance = pd.read_excel('Pre Processing/finance.xlsx', index_col=0)\n","df_tech = pd.read_excel('Pre Processing/tech.xlsx', index_col=0)"]},{"cell_type":"markdown","metadata":{},"source":["Remark: For smooth code execution, it is recommended to download all the excel files required in a folder named \"Pre Processing\" and the folder should be in the same directory as this Jupyter Notebook file. Otherwise, it is necessary to change the file paths accordingly."]},{"cell_type":"markdown","metadata":{"id":"SkqjImCyg11m"},"source":["# Merging the dataframes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZb9QtDCg3le"},"outputs":[],"source":["# We merge all the sectors into one dataframe\n","frames = [df_auto, df_fashion, df_finance, df_tech]\n","df = pd.concat(frames)"]},{"cell_type":"markdown","metadata":{"id":"x4UXMrZGhFGv"},"source":["# Data pre-processing"]},{"cell_type":"markdown","metadata":{"id":"Kz1wM_FOhN58"},"source":["### Dropping duplicate rows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3497,"status":"ok","timestamp":1637758410680,"user":{"displayName":"Selim Mouaffak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7hSiofTadGlhaAhY7NhLkOUuHCsHhw3XP7YBc3w=s64","userId":"09406084547179617328"},"user_tz":-60},"id":"OPy1VnKRhm0w","outputId":"ebbc35d1-6583-4b3a-cc46-4a2d9dd3d1f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape before :  (129866, 6)\n","Number of duplicated rows :  2654\n","Shape after :  (127212, 6)\n"]}],"source":["# We drop duplicate rows as they hold redundant information\n","print('Shape before : ', df.shape)\n","print('Number of duplicated rows : ', df[df.duplicated()].shape[0])\n","df = df.drop_duplicates()\n","print('Shape after : ', df.shape)"]},{"cell_type":"markdown","metadata":{"id":"n9wtB10QiFqa"},"source":["### Dropping sources and companies under threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Weqvr9WfiRhx"},"outputs":[],"source":["thresh_source = 30\n","thresh_company = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637758410681,"user":{"displayName":"Selim Mouaffak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7hSiofTadGlhaAhY7NhLkOUuHCsHhw3XP7YBc3w=s64","userId":"09406084547179617328"},"user_tz":-60},"id":"z6tTe2PnibB1","outputId":"cd0aa396-0877-4f46-b483-4c309325caef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of sources remaining => 75\n","(127090, 6)\n"]}],"source":["# Dropping sources that wrote less than thresh_source articles\n","df = df.groupby('source').filter(lambda x: len(x) > thresh_source).reset_index(drop=True)\n","print('Number of sources remaining =>',len(df['source'].unique()))\n","print(df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1637758411001,"user":{"displayName":"Selim Mouaffak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7hSiofTadGlhaAhY7NhLkOUuHCsHhw3XP7YBc3w=s64","userId":"09406084547179617328"},"user_tz":-60},"id":"eRaTYB4qiehy","outputId":"5d48e5bb-6649-4b04-a19f-e9afc88d0b7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of companies remaining => 75\n","(127048, 6)\n"]}],"source":["# Dropping companies that have less than thresh_company artciles about them\n","df = df.groupby('company').filter(lambda x: len(x) > thresh_company).reset_index(drop=True)\n","print('Number of companies remaining =>',len(df['company'].unique()))\n","print(df.shape)"]},{"cell_type":"markdown","metadata":{"id":"G1yEfNC6irtZ"},"source":["### Basic pre-processing steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zX_BT6efizYe"},"outputs":[],"source":["# Functions that removes stopwords from text\n","stoplist= set(stopwords.words(\"english\"))\n","\n","def remove_stopwords(text):\n","    tokens= word_tokenize(text)\n","    res = \" \".join(w.lower() for w in tokens if not w.lower() in stoplist)\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vL8fHcgxi2m5"},"outputs":[],"source":["# Removes all special characters and numericals leaving the alphabets\n","def clean(text):\n","    text = re.sub('[^A-Za-z]+', ' ', text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dr24IG9Ni8aq"},"outputs":[],"source":["# Removes all punctuation that is irrelevant for textual analysis\n","def remove_punctuation(text):\n","    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\",  \"!\",'\"'))\n","    return final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUqJ3j3wi9Sc"},"outputs":[],"source":["# Function that lemmatizes the text\n","lemmatizer = WordNetLemmatizer()\n","\n","def lemmatize_sentence(text):\n","  word_list = nltk.word_tokenize(text)\n","  lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n","  return lemmatized_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lV9ja3ajB_a"},"outputs":[],"source":["# Function that formats string to become more readable\n","def format_strings(text):\n","  text = re.sub('[^A-Za-z0-9]', ' ', text)\n","  return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mntj4aygi_Sy"},"outputs":[],"source":["# Function that applies all previously mentioned steps\n","def pre_processing(text):\n","    text = remove_punctuation(text)\n","    text = clean(text)\n","    text = remove_stopwords(text)\n","    text = lemmatize_sentence(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1jrx0HujBe7"},"outputs":[],"source":["# We apply the pre-processing on the articles and we format the source and title\n","df['text'] = df['text'].apply(pre_processing)\n","df['source'] = df['source'].apply(format_strings)\n","df['title'] = df['title'].apply(format_strings)"]},{"cell_type":"markdown","metadata":{"id":"vRTZ4BXlrAnJ"},"source":["# Save output to xlsx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jC1j4hoErDUX"},"outputs":[],"source":["# We save pre-processed output to xlsx to be able to re-use it\n","df.to_excel('Pre Processing/clean_dataset.xlsx', index=False)"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["SkqjImCyg11m","n9wtB10QiFqa"],"name":"Data_pre_processing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
